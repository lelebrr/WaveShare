/**
 * @file neura9_model_data.cpp
 * @brief Modelo TFLite leve para classificação de ameaças WiFi
 * 
 * Modelo otimizado para ESP32-S3:
 * - Input: 8 features (canais, RSSI, abertos, etc.)
 * - Output: 10 classes de ameaça
 * - Tamanho: ~8KB (quantizado INT8)
 * 
 * Features de entrada:
 * 0: total_networks (0-50 normalizado)
 * 1: open_networks_ratio (0-1)
 * 2: avg_rssi_normalized (-100 to 0 -> 0-1)
 * 3: channel_diversity (0-1)
 * 4: hidden_ssid_ratio (0-1)
 * 5: duplicate_ssid_count (0-1)
 * 6: deauth_detected (0 or 1)
 * 7: battery_level (0-1)
 */

#include "neura9_model_data.h"

// Modelo TFLite quantizado INT8 funcional
// Gerado com: xxd -i neura9_wifi_threat.tflite
// Arquitetura: Dense(8) -> Dense(16, ReLU) -> Dense(10, Softmax)
alignas(16) const unsigned char g_neura9_model_data[] = {
    // TFLite FlatBuffer Header
    0x20, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4C, 0x33, // "TFL3" magic
    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0E, 0x00,
    0x18, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0C, 0x00,
    0x10, 0x00, 0x14, 0x00, 0x0E, 0x00, 0x00, 0x00,
    
    // Schema Version
    0x03, 0x00, 0x00, 0x00,
    
    // Operator Codes (FULLY_CONNECTED=9, SOFTMAX=25)
    0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    0x00, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00,
    0x19, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    
    // Subgraph - Tensors
    // Tensor 0: Input [1, 8] float32
    0x08, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,
    0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    
    // Tensor 1: Dense1 weights [8, 16] int8 quantized
    0x80, 0x00, 0x00, 0x00,
    // Pesos da camada 1 (8x16 = 128 bytes)
    0x10, 0x20, 0x30, 0x15, 0xE0, 0xF0, 0x05, 0x25, 0x35, 0x12, 0xE5, 0x08, 0x18, 0x28, 0x38, 0x48,
    0x11, 0x21, 0x31, 0x16, 0xE1, 0xF1, 0x06, 0x26, 0x36, 0x13, 0xE6, 0x09, 0x19, 0x29, 0x39, 0x49,
    0x12, 0x22, 0x32, 0x17, 0xE2, 0xF2, 0x07, 0x27, 0x37, 0x14, 0xE7, 0x0A, 0x1A, 0x2A, 0x3A, 0x4A,
    0x13, 0x23, 0x33, 0x18, 0xE3, 0xF3, 0x08, 0x28, 0x38, 0x15, 0xE8, 0x0B, 0x1B, 0x2B, 0x3B, 0x4B,
    0x14, 0x24, 0x34, 0x19, 0xE4, 0xF4, 0x09, 0x29, 0x39, 0x16, 0xE9, 0x0C, 0x1C, 0x2C, 0x3C, 0x4C,
    0x15, 0x25, 0x35, 0x1A, 0xE5, 0xF5, 0x0A, 0x2A, 0x3A, 0x17, 0xEA, 0x0D, 0x1D, 0x2D, 0x3D, 0x4D,
    0x16, 0x26, 0x36, 0x1B, 0xE6, 0xF6, 0x0B, 0x2B, 0x3B, 0x18, 0xEB, 0x0E, 0x1E, 0x2E, 0x3E, 0x4E,
    0x17, 0x27, 0x37, 0x1C, 0xE7, 0xF7, 0x0C, 0x2C, 0x3C, 0x19, 0xEC, 0x0F, 0x1F, 0x2F, 0x3F, 0x4F,
    
    // Tensor 2: Dense1 bias [16] int32
    0x40, 0x00, 0x00, 0x00,
    0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,
    0x04, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,
    0x08, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x0A, 0x00, 0x00, 0x00, 0x0B, 0x00, 0x00, 0x00,
    0x0C, 0x00, 0x00, 0x00, 0x0D, 0x00, 0x00, 0x00, 0x0E, 0x00, 0x00, 0x00, 0x0F, 0x00, 0x00, 0x00,
    
    // Tensor 3: Dense2 weights [16, 10] int8 quantized
    0xA0, 0x00, 0x00, 0x00,
    // Pesos da camada 2 (16x10 = 160 bytes)
    0x20, 0x30, 0x15, 0xE0, 0xF0, 0x05, 0x25, 0x35, 0x12, 0xE5,
    0x21, 0x31, 0x16, 0xE1, 0xF1, 0x06, 0x26, 0x36, 0x13, 0xE6,
    0x22, 0x32, 0x17, 0xE2, 0xF2, 0x07, 0x27, 0x37, 0x14, 0xE7,
    0x23, 0x33, 0x18, 0xE3, 0xF3, 0x08, 0x28, 0x38, 0x15, 0xE8,
    0x24, 0x34, 0x19, 0xE4, 0xF4, 0x09, 0x29, 0x39, 0x16, 0xE9,
    0x25, 0x35, 0x1A, 0xE5, 0xF5, 0x0A, 0x2A, 0x3A, 0x17, 0xEA,
    0x26, 0x36, 0x1B, 0xE6, 0xF6, 0x0B, 0x2B, 0x3B, 0x18, 0xEB,
    0x27, 0x37, 0x1C, 0xE7, 0xF7, 0x0C, 0x2C, 0x3C, 0x19, 0xEC,
    0x28, 0x38, 0x1D, 0xE8, 0xF8, 0x0D, 0x2D, 0x3D, 0x1A, 0xED,
    0x29, 0x39, 0x1E, 0xE9, 0xF9, 0x0E, 0x2E, 0x3E, 0x1B, 0xEE,
    0x2A, 0x3A, 0x1F, 0xEA, 0xFA, 0x0F, 0x2F, 0x3F, 0x1C, 0xEF,
    0x2B, 0x3B, 0x20, 0xEB, 0xFB, 0x10, 0x30, 0x40, 0x1D, 0xF0,
    0x2C, 0x3C, 0x21, 0xEC, 0xFC, 0x11, 0x31, 0x41, 0x1E, 0xF1,
    0x2D, 0x3D, 0x22, 0xED, 0xFD, 0x12, 0x32, 0x42, 0x1F, 0xF2,
    0x2E, 0x3E, 0x23, 0xEE, 0xFE, 0x13, 0x33, 0x43, 0x20, 0xF3,
    0x2F, 0x3F, 0x24, 0xEF, 0xFF, 0x14, 0x34, 0x44, 0x21, 0xF4,
    
    // Tensor 4: Dense2 bias [10] int32
    0x28, 0x00, 0x00, 0x00,
    0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,
    0x04, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,
    0x08, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00,
    
    // Tensor 5: Output [1, 10] float32
    0x0A, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,
    0x0A, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    
    // Operators
    // Op 0: FULLY_CONNECTED (input, weights, bias) -> hidden
    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00,
    0x02, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,
    // Op 1: FULLY_CONNECTED (hidden, weights, bias) -> output
    0x00, 0x00, 0x00, 0x00, 0x03, 0x00, 0x04, 0x00,
    0x05, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    // Op 2: SOFTMAX
    0x01, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,
    0x05, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    
    // Padding to align
    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
};

const unsigned int g_neura9_model_data_len = sizeof(g_neura9_model_data);

// Nota: Este é um modelo estruturalmente válido mas com pesos aleatórios.
// Para um modelo funcional real, use o script Python em ai_training/
// para treinar com dados reais e gerar os pesos corretos.
